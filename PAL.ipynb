{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create sample data if file doesn't exist\n",
        "# In real-world scenario, you would use your actual dataset\n",
        "try:\n",
        "    # Try to load the file\n",
        "    df = pd.read_csv('2012-2013-data-with-predictions-4-final.csv', encoding='latin1', on_bad_lines='skip')\n",
        "except:\n",
        "    print(\"Dataset not found. Creating synthetic data for demonstration...\")\n",
        "    # Create synthetic data that mimics educational data\n",
        "    np.random.seed(42)\n",
        "    n_samples = 10000\n",
        "\n",
        "    # Generate synthetic features\n",
        "    skill_names = np.random.randint(0, 20, n_samples)  # 20 different skills\n",
        "    attempt_counts = np.random.randint(1, 10, n_samples)\n",
        "    ms_first_response = np.random.randint(1000, 30000, n_samples)  # time in milliseconds\n",
        "    tutor_modes = np.random.randint(0, 3, n_samples)  # 3 different tutor modes\n",
        "\n",
        "    # Generate target based on a simple rule with some noise\n",
        "    # Students are more likely to be correct if:\n",
        "    # - They've had more attempts (practice effect)\n",
        "    # - They respond quickly (indicating confidence)\n",
        "    # - They're in certain tutor modes\n",
        "    p_correct = 0.3 + 0.05 * attempt_counts + 20000 / (ms_first_response + 5000) + 0.1 * (tutor_modes == 1)\n",
        "    p_correct = np.clip(p_correct, 0.1, 0.9)  # Keep probabilities reasonable\n",
        "    correct = np.random.binomial(1, p_correct)\n",
        "\n",
        "    # Create user_ids\n",
        "    user_ids = np.random.randint(1000, 5000, n_samples)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'user_id': user_ids,\n",
        "        'skill_name': [f\"Skill_{i}\" for i in skill_names],\n",
        "        'correct': correct,\n",
        "        'attempt_count': attempt_counts,\n",
        "        'ms_first_response': ms_first_response,\n",
        "        'tutor_mode': [f\"Mode_{i}\" for i in tutor_modes]\n",
        "    })\n",
        "\n",
        "print(\"Initial Data Sample:\")\n",
        "display(df.head())\n",
        "\n",
        "# Basic data preprocessing\n",
        "print(\"\\nData Overview:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values\n",
        "df_cleaned = df.dropna()\n",
        "print(f\"\\nShape after dropping missing values: {df_cleaned.shape}\")\n",
        "\n",
        "# Encode categorical variables\n",
        "df_cleaned['skill_name_code'] = df_cleaned['skill_name'].astype('category').cat.codes\n",
        "df_cleaned['tutor_mode_code'] = df_cleaned['tutor_mode'].astype('category').cat.codes\n",
        "\n",
        "# Feature engineering\n",
        "print(\"\\nFeature Engineering:\")\n",
        "# Converting response time to seconds for better interpretability\n",
        "df_cleaned['response_time_sec'] = df_cleaned['ms_first_response'] / 1000\n",
        "# Creating a new feature for response speed category\n",
        "df_cleaned['response_speed'] = pd.cut(\n",
        "    df_cleaned['response_time_sec'],\n",
        "    bins=[0, 5, 15, 30, float('inf')],\n",
        "    labels=['very_fast', 'fast', 'medium', 'slow']\n",
        ")\n",
        "\n",
        "# Data visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot 1: Correct answers by attempt count\n",
        "plt.subplot(1, 2, 1)\n",
        "attempt_success = df_cleaned.groupby('attempt_count')['correct'].mean()\n",
        "attempt_success.plot(kind='bar', color='skyblue')\n",
        "plt.title('Success Rate by Attempt Count')\n",
        "plt.xlabel('Number of Attempts')\n",
        "plt.ylabel('Success Rate')\n",
        "\n",
        "# Plot 2: Response time distribution by correctness\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(data=df_cleaned, x='response_time_sec', hue='correct',\n",
        "             bins=30, kde=True, element=\"step\", common_norm=False,\n",
        "             stat=\"density\", log_scale=(False, True))\n",
        "plt.title('Response Time Distribution by Correctness')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.ylabel('Density')\n",
        "plt.xlim(0, 60)  # Limit to 60 seconds for better visualization\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature Selection for ML\n",
        "print(\"\\nPreparing features for machine learning...\")\n",
        "features = [\n",
        "    'skill_name_code',\n",
        "    'attempt_count',\n",
        "    'ms_first_response',\n",
        "    'tutor_mode_code'\n",
        "]\n",
        "\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned['correct']\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create a pipeline with preprocessing and model\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [50, 100],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Run grid search with cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1\n",
        ")\n",
        "print(\"\\nPerforming grid search for hyperparameter tuning...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Feature importance\n",
        "if hasattr(best_model[-1], 'feature_importances_'):\n",
        "    importances = best_model[-1].feature_importances_\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(\"Feature Importances\")\n",
        "    plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
        "    plt.xticks(range(X.shape[1]), [X.columns[i] for i in indices], rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create a function for predictions\n",
        "def predict_performance(model, skill_name_code, attempts, ms_time, tutor_mode_code):\n",
        "    \"\"\"\n",
        "    Predict student performance based on input features\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model: trained sklearn model\n",
        "    skill_name_code: int, encoded skill name\n",
        "    attempts: int, number of attempts\n",
        "    ms_time: int, response time in milliseconds\n",
        "    tutor_mode_code: int, encoded tutor mode\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    prediction: str, \"Correct\" or \"Incorrect\"\n",
        "    probability: float, probability of being correct\n",
        "    \"\"\"\n",
        "    input_data = pd.DataFrame([{\n",
        "        'skill_name_code': skill_name_code,\n",
        "        'attempt_count': attempts,\n",
        "        'ms_first_response': ms_time,\n",
        "        'tutor_mode_code': tutor_mode_code\n",
        "    }])\n",
        "\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    probability = model.predict_proba(input_data)[0][1]  # Probability of being correct\n",
        "\n",
        "    return \"Correct\" if prediction == 1 else \"Incorrect\", probability\n",
        "\n",
        "# Example prediction\n",
        "skill_code = 10\n",
        "attempts = 3\n",
        "response_time = 5000  # ms\n",
        "tutor_mode = 1\n",
        "\n",
        "result, prob = predict_performance(best_model, skill_code, attempts, response_time, tutor_mode)\n",
        "print(f\"\\nPrediction for test input (skill={skill_code}, attempts={attempts}, response_time={response_time}ms, tutor_mode={tutor_mode}):\")\n",
        "print(f\"Prediction: {result} (Probability of being correct: {prob:.2f})\")\n",
        "\n",
        "# Create a simple interactive prediction function\n",
        "def interactive_predictions(model, df):\n",
        "    \"\"\"Run predictions with different parameter combinations\"\"\"\n",
        "    # Get unique values from the dataset\n",
        "    unique_skills = sorted(df['skill_name_code'].unique())\n",
        "    min_attempts = int(df['attempt_count'].min())\n",
        "    max_attempts = int(df['attempt_count'].min())\n",
        "    min_time = int(df['ms_first_response'].min())\n",
        "    max_time = int(df['ms_first_response'].max())\n",
        "    unique_modes = sorted(df['tutor_mode_code'].unique())\n",
        "\n",
        "    # Create a grid of combinations\n",
        "    print(\"\\nPredictions for various parameter combinations:\")\n",
        "    print(\"-----------------------------------------------\")\n",
        "    print(f\"{'Skill':<6} {'Attempts':<10} {'Response Time':<15} {'Tutor Mode':<12} {'Prediction':<12} {'Probability':<12}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Sample some combinations\n",
        "    for skill in unique_skills[:3]:  # First 3 skills\n",
        "        for attempts in [1, 3, 5]:\n",
        "            for time in [2000, 10000, 20000]:\n",
        "                for mode in unique_modes[:2]:  # First 2 modes\n",
        "                    result, prob = predict_performance(model, skill, attempts, time, mode)\n",
        "                    print(f\"{skill:<6} {attempts:<10} {time:<15} {mode:<12} {result:<12} {prob:.2f}\")\n",
        "\n",
        "# Run the interactive predictions\n",
        "interactive_predictions(best_model, df_cleaned)\n",
        "\n",
        "# Save the model for future use\n",
        "import joblib\n",
        "joblib.dump(best_model, 'student_performance_model.pkl')\n",
        "print(\"\\nModel saved as 'student_performance_model.pkl'\")\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"1. Created a robust student performance prediction model\")\n",
        "print(\"2. Performed feature engineering and visualization\")\n",
        "print(\"3. Used hyperparameter tuning to optimize the model\")\n",
        "print(\"4. Evaluated model performance with classification metrics and ROC curve\")\n",
        "print(\"5. Built a prediction function for real-time assessment\")\n",
        "print(\"6. Saved the model for future use\")"
      ],
      "metadata": {
        "id": "M6fa5P5eFfdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create sample data if file doesn't exist\n",
        "# In real-world scenario, you would use your actual dataset\n",
        "try:\n",
        "    # Try to load the file\n",
        "    df = pd.read_csv('2012-2013-data-with-predictions-4-final.csv', encoding='latin1', on_bad_lines='skip')\n",
        "except:\n",
        "    print(\"Dataset not found. Creating synthetic data for demonstration...\")\n",
        "    # Create synthetic data that mimics educational data\n",
        "    np.random.seed(42)\n",
        "    n_samples = 10000\n",
        "\n",
        "    # Generate synthetic features\n",
        "    skill_names = np.random.randint(0, 20, n_samples)  # 20 different skills\n",
        "    attempt_counts = np.random.randint(1, 10, n_samples)\n",
        "    ms_first_response = np.random.randint(1000, 30000, n_samples)  # time in milliseconds\n",
        "    tutor_modes = np.random.randint(0, 3, n_samples)  # 3 different tutor modes\n",
        "\n",
        "    # Generate target based on a simple rule with some noise\n",
        "    # Students are more likely to be correct if:\n",
        "    # - They've had more attempts (practice effect)\n",
        "    # - They respond quickly (indicating confidence)\n",
        "    # - They're in certain tutor modes\n",
        "    p_correct = 0.3 + 0.05 * attempt_counts + 20000 / (ms_first_response + 5000) + 0.1 * (tutor_modes == 1)\n",
        "    p_correct = np.clip(p_correct, 0.1, 0.9)  # Keep probabilities reasonable\n",
        "    correct = np.random.binomial(1, p_correct)\n",
        "\n",
        "    # Create user_ids\n",
        "    user_ids = np.random.randint(1000, 5000, n_samples)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'user_id': user_ids,\n",
        "        'skill_name': [f\"Skill_{i}\" for i in skill_names],\n",
        "        'correct': correct,\n",
        "        'attempt_count': attempt_counts,\n",
        "        'ms_first_response': ms_first_response,\n",
        "        'tutor_mode': [f\"Mode_{i}\" for i in tutor_modes]\n",
        "    })\n",
        "\n",
        "print(\"Initial Data Sample:\")\n",
        "display(df.head())\n",
        "\n",
        "# Basic data preprocessing\n",
        "print(\"\\nData Overview:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values\n",
        "df_cleaned = df.dropna()\n",
        "print(f\"\\nShape after dropping missing values: {df_cleaned.shape}\")\n",
        "\n",
        "# Encode categorical variables\n",
        "df_cleaned['skill_name_code'] = df_cleaned['skill_name'].astype('category').cat.codes\n",
        "df_cleaned['tutor_mode_code'] = df_cleaned['tutor_mode'].astype('category').cat.codes\n",
        "\n",
        "# Feature engineering\n",
        "print(\"\\nFeature Engineering:\")\n",
        "# Converting response time to seconds for better interpretability\n",
        "df_cleaned['response_time_sec'] = df_cleaned['ms_first_response'] / 1000\n",
        "# Creating a new feature for response speed category\n",
        "df_cleaned['response_speed'] = pd.cut(\n",
        "    df_cleaned['response_time_sec'],\n",
        "    bins=[0, 5, 15, 30, float('inf')],\n",
        "    labels=['very_fast', 'fast', 'medium', 'slow']\n",
        ")\n",
        "\n",
        "# Data visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot 1: Correct answers by attempt count\n",
        "plt.subplot(1, 2, 1)\n",
        "attempt_success = df_cleaned.groupby('attempt_count')['correct'].mean()\n",
        "attempt_success.plot(kind='bar', color='skyblue')\n",
        "plt.title('Success Rate by Attempt Count')\n",
        "plt.xlabel('Number of Attempts')\n",
        "plt.ylabel('Success Rate')\n",
        "\n",
        "# Plot 2: Response time distribution by correctness\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(data=df_cleaned, x='response_time_sec', hue='correct',\n",
        "             bins=30, kde=True, element=\"step\", common_norm=False,\n",
        "             stat=\"density\", log_scale=(False, True))\n",
        "plt.title('Response Time Distribution by Correctness')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.ylabel('Density')\n",
        "plt.xlim(0, 60)  # Limit to 60 seconds for better visualization\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature Selection for ML\n",
        "print(\"\\nPreparing features for machine learning...\")\n",
        "features = [\n",
        "    'skill_name_code',\n",
        "    'attempt_count',\n",
        "    'ms_first_response',\n",
        "    'tutor_mode_code'\n",
        "]\n",
        "\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned['correct']\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create a pipeline with preprocessing and model\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [50, 100],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Run grid search with cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1\n",
        ")\n",
        "print(\"\\nPerforming grid search for hyperparameter tuning...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Feature importance\n",
        "if hasattr(best_model[-1], 'feature_importances_'):\n",
        "    importances = best_model[-1].feature_importances_\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(\"Feature Importances\")\n",
        "    plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
        "    plt.xticks(range(X.shape[1]), [X.columns[i] for i in indices], rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create a function for predictions\n",
        "def predict_performance(model, skill_name_code, attempts, ms_time, tutor_mode_code):\n",
        "    \"\"\"\n",
        "    Predict student performance based on input features\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model: trained sklearn model\n",
        "    skill_name_code: int, encoded skill name\n",
        "    attempts: int, number of attempts\n",
        "    ms_time: int, response time in milliseconds\n",
        "    tutor_mode_code: int, encoded tutor mode\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    prediction: str, \"Correct\" or \"Incorrect\"\n",
        "    probability: float, probability of being correct\n",
        "    \"\"\"\n",
        "    input_data = pd.DataFrame([{\n",
        "        'skill_name_code': skill_name_code,\n",
        "        'attempt_count': attempts,\n",
        "        'ms_first_response': ms_time,\n",
        "        'tutor_mode_code': tutor_mode_code\n",
        "    }])\n",
        "\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    probability = model.predict_proba(input_data)[0][1]  # Probability of being correct\n",
        "\n",
        "    return \"Correct\" if prediction == 1 else \"Incorrect\", probability\n",
        "\n",
        "# Example prediction\n",
        "skill_code = 10\n",
        "attempts = 3\n",
        "response_time = 5000  # ms\n",
        "tutor_mode = 1\n",
        "\n",
        "result, prob = predict_performance(best_model, skill_code, attempts, response_time, tutor_mode)\n",
        "print(f\"\\nPrediction for test input (skill={skill_code}, attempts={attempts}, response_time={response_time}ms, tutor_mode={tutor_mode}):\")\n",
        "print(f\"Prediction: {result} (Probability of being correct: {prob:.2f})\")\n",
        "\n",
        "# Create a simple interactive prediction function\n",
        "def interactive_predictions(model, df):\n",
        "    \"\"\"Run predictions with different parameter combinations\"\"\"\n",
        "    # Get unique values from the dataset\n",
        "    unique_skills = sorted(df['skill_name_code'].unique())\n",
        "    min_attempts = int(df['attempt_count'].min())\n",
        "    max_attempts = int(df['attempt_count'].min())\n",
        "    min_time = int(df['ms_first_response'].min())\n",
        "    max_time = int(df['ms_first_response'].max())\n",
        "    unique_modes = sorted(df['tutor_mode_code'].unique())\n",
        "\n",
        "    # Create a grid of combinations\n",
        "    print(\"\\nPredictions for various parameter combinations:\")\n",
        "    print(\"-----------------------------------------------\")\n",
        "    print(f\"{'Skill':<6} {'Attempts':<10} {'Response Time':<15} {'Tutor Mode':<12} {'Prediction':<12} {'Probability':<12}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Sample some combinations\n",
        "    for skill in unique_skills[:3]:  # First 3 skills\n",
        "        for attempts in [1, 3, 5]:\n",
        "            for time in [2000, 10000, 20000]:\n",
        "                for mode in unique_modes[:2]:  # First 2 modes\n",
        "                    result, prob = predict_performance(model, skill, attempts, time, mode)\n",
        "                    print(f\"{skill:<6} {attempts:<10} {time:<15} {mode:<12} {result:<12} {prob:.2f}\")\n",
        "\n",
        "# Run the interactive predictions\n",
        "interactive_predictions(best_model, df_cleaned)\n",
        "\n",
        "# Save the model for future use\n",
        "import joblib\n",
        "joblib.dump(best_model, 'student_performance_model.pkl')\n",
        "print(\"\\nModel saved as 'student_performance_model.pkl'\")\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"1. Created a robust student performance prediction model\")\n",
        "print(\"2. Performed feature engineering and visualization\")\n",
        "print(\"3. Used hyperparameter tuning to optimize the model\")\n",
        "print(\"4. Evaluated model performance with classification metrics and ROC curve\")\n",
        "print(\"5. Built a prediction function for real-time assessment\")\n",
        "print(\"6. Saved the model for future use\")"
      ],
      "metadata": {
        "id": "RD6BFO_dHm1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}